{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_CBOW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SangMin316/NLP/blob/main/pytorch_CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9HKOKQHxBFH"
      },
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBUmB3yIMgzB",
        "outputId": "1e19ed68-2ff7-441c-d0bd-ffa4fbe02601"
      },
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihvJqrz4xH3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4eba78-6f49-4ddd-cff9-777b37b5b8c6"
      },
      "source": [
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right (window size)\n",
        "EMDEDDING_DIM = 100  # word vector의 dimension\n",
        "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
        "Computational processes are abstract beings that inhabit computers.\n",
        "As they evolve, processes manipulate other abstract things called data.\n",
        "The evolution of a process is directed by a pattern ofS rules\n",
        "called a program. People create programs to direct processes. In effect,\n",
        "we conjure the spirits of the computer with our spells.\"\"\".split() \n",
        "# split()은 공백을 기준으로 토큰화 시키는 것\n",
        "print(raw_text)\n",
        "print(len(raw_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['We', 'are', 'about', 'to', 'study', 'the', 'idea', 'of', 'a', 'computational', 'process.', 'Computational', 'processes', 'are', 'abstract', 'beings', 'that', 'inhabit', 'computers.', 'As', 'they', 'evolve,', 'processes', 'manipulate', 'other', 'abstract', 'things', 'called', 'data.', 'The', 'evolution', 'of', 'a', 'process', 'is', 'directed', 'by', 'a', 'pattern', 'ofS', 'rules', 'called', 'a', 'program.', 'People', 'create', 'programs', 'to', 'direct', 'processes.', 'In', 'effect,', 'we', 'conjure', 'the', 'spirits', 'of', 'the', 'computer', 'with', 'our', 'spells.']\n",
            "62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqFhiqQHxLz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a44d4060-1a3d-4d9a-dccb-2ea6a76acfe0"
      },
      "source": [
        "# By deriving a set from `raw_text`, we deduplicate the array\n",
        "vocab = set(raw_text) # set은 중복 없애줌\n",
        "print(vocab)\n",
        "vocab_size = len(vocab)\n",
        "print(vocab_size)\n",
        "\n",
        "#dictionary 구조이고, key를 word로 value값를 idx로\n",
        "word_to_idx = {word:idx for idx, word in enumerate(vocab)}\n",
        "print('word_to_idx:',word_to_idx)\n",
        "# word 를 index해주는거 \n",
        "# word_to_idx = {}\n",
        "# for idx, word in enumerate(vocab):\n",
        "#   word_to_idx[word] = idx # key 값을 [word] 그에 해당하는 값을 idx\n",
        "\n",
        "idx_to_word = {idx:word for idx, word in enumerate(vocab)} \n",
        "print('idx_to_word:',idx_to_word)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data.', 'about', 'beings', 'pattern', 'computer', 'The', 'In', 'our', 'other', 'inhabit', 'study', 'create', 'Computational', 'processes.', 'are', 'we', 'conjure', 'spells.', 'process', 'We', 'they', 'evolution', 'by', 'idea', 'things', 'processes', 'effect,', 'People', 'to', 'that', 'evolve,', 'programs', 'spirits', 'abstract', 'process.', 'manipulate', 'called', 'program.', 'a', 'with', 'computational', 'directed', 'is', 'direct', 'As', 'of', 'ofS', 'the', 'rules', 'computers.'}\n",
            "50\n",
            "word_to_idx: {'data.': 0, 'about': 1, 'beings': 2, 'pattern': 3, 'computer': 4, 'The': 5, 'In': 6, 'our': 7, 'other': 8, 'inhabit': 9, 'study': 10, 'create': 11, 'Computational': 12, 'processes.': 13, 'are': 14, 'we': 15, 'conjure': 16, 'spells.': 17, 'process': 18, 'We': 19, 'they': 20, 'evolution': 21, 'by': 22, 'idea': 23, 'things': 24, 'processes': 25, 'effect,': 26, 'People': 27, 'to': 28, 'that': 29, 'evolve,': 30, 'programs': 31, 'spirits': 32, 'abstract': 33, 'process.': 34, 'manipulate': 35, 'called': 36, 'program.': 37, 'a': 38, 'with': 39, 'computational': 40, 'directed': 41, 'is': 42, 'direct': 43, 'As': 44, 'of': 45, 'ofS': 46, 'the': 47, 'rules': 48, 'computers.': 49}\n",
            "idx_to_word: {0: 'data.', 1: 'about', 2: 'beings', 3: 'pattern', 4: 'computer', 5: 'The', 6: 'In', 7: 'our', 8: 'other', 9: 'inhabit', 10: 'study', 11: 'create', 12: 'Computational', 13: 'processes.', 14: 'are', 15: 'we', 16: 'conjure', 17: 'spells.', 18: 'process', 19: 'We', 20: 'they', 21: 'evolution', 22: 'by', 23: 'idea', 24: 'things', 25: 'processes', 26: 'effect,', 27: 'People', 28: 'to', 29: 'that', 30: 'evolve,', 31: 'programs', 32: 'spirits', 33: 'abstract', 34: 'process.', 35: 'manipulate', 36: 'called', 37: 'program.', 38: 'a', 39: 'with', 40: 'computational', 41: 'directed', 42: 'is', 43: 'direct', 44: 'As', 45: 'of', 46: 'ofS', 47: 'the', 48: 'rules', 49: 'computers.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btlCQUx6nafW",
        "outputId": "919569cd-f386-43e3-9287-fe43617d7aa0"
      },
      "source": [
        "data = []\n",
        "for i in range(2, len(raw_text) - 2):\n",
        "    context = [raw_text[i - 2], raw_text[i - 1],\n",
        "               raw_text[i + 1], raw_text[i + 2]]\n",
        "    target = raw_text[i]\n",
        "    data.append((context, target))\n",
        "print('data:',data)\n",
        "# 중심단어와 그에 해당하는 앞뒤 두개 단어를 하나로 받아둠"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea'), (['the', 'idea', 'a', 'computational'], 'of'), (['idea', 'of', 'computational', 'process.'], 'a'), (['of', 'a', 'process.', 'Computational'], 'computational'), (['a', 'computational', 'Computational', 'processes'], 'process.'), (['computational', 'process.', 'processes', 'are'], 'Computational'), (['process.', 'Computational', 'are', 'abstract'], 'processes'), (['Computational', 'processes', 'abstract', 'beings'], 'are'), (['processes', 'are', 'beings', 'that'], 'abstract'), (['are', 'abstract', 'that', 'inhabit'], 'beings'), (['abstract', 'beings', 'inhabit', 'computers.'], 'that'), (['beings', 'that', 'computers.', 'As'], 'inhabit'), (['that', 'inhabit', 'As', 'they'], 'computers.'), (['inhabit', 'computers.', 'they', 'evolve,'], 'As'), (['computers.', 'As', 'evolve,', 'processes'], 'they'), (['As', 'they', 'processes', 'manipulate'], 'evolve,'), (['they', 'evolve,', 'manipulate', 'other'], 'processes'), (['evolve,', 'processes', 'other', 'abstract'], 'manipulate'), (['processes', 'manipulate', 'abstract', 'things'], 'other'), (['manipulate', 'other', 'things', 'called'], 'abstract'), (['other', 'abstract', 'called', 'data.'], 'things'), (['abstract', 'things', 'data.', 'The'], 'called'), (['things', 'called', 'The', 'evolution'], 'data.'), (['called', 'data.', 'evolution', 'of'], 'The'), (['data.', 'The', 'of', 'a'], 'evolution'), (['The', 'evolution', 'a', 'process'], 'of'), (['evolution', 'of', 'process', 'is'], 'a'), (['of', 'a', 'is', 'directed'], 'process'), (['a', 'process', 'directed', 'by'], 'is'), (['process', 'is', 'by', 'a'], 'directed'), (['is', 'directed', 'a', 'pattern'], 'by'), (['directed', 'by', 'pattern', 'ofS'], 'a'), (['by', 'a', 'ofS', 'rules'], 'pattern'), (['a', 'pattern', 'rules', 'called'], 'ofS'), (['pattern', 'ofS', 'called', 'a'], 'rules'), (['ofS', 'rules', 'a', 'program.'], 'called'), (['rules', 'called', 'program.', 'People'], 'a'), (['called', 'a', 'People', 'create'], 'program.'), (['a', 'program.', 'create', 'programs'], 'People'), (['program.', 'People', 'programs', 'to'], 'create'), (['People', 'create', 'to', 'direct'], 'programs'), (['create', 'programs', 'direct', 'processes.'], 'to'), (['programs', 'to', 'processes.', 'In'], 'direct'), (['to', 'direct', 'In', 'effect,'], 'processes.'), (['direct', 'processes.', 'effect,', 'we'], 'In'), (['processes.', 'In', 'we', 'conjure'], 'effect,'), (['In', 'effect,', 'conjure', 'the'], 'we'), (['effect,', 'we', 'the', 'spirits'], 'conjure'), (['we', 'conjure', 'spirits', 'of'], 'the'), (['conjure', 'the', 'of', 'the'], 'spirits'), (['the', 'spirits', 'the', 'computer'], 'of'), (['spirits', 'of', 'computer', 'with'], 'the'), (['of', 'the', 'with', 'our'], 'computer'), (['the', 'computer', 'our', 'spells.'], 'with')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7MX6WJBtMy-",
        "outputId": "86fbc7d3-fab6-442f-9368-0b9c98021c74"
      },
      "source": [
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea'), (['the', 'idea', 'a', 'computational'], 'of'), (['idea', 'of', 'computational', 'process.'], 'a'), (['of', 'a', 'process.', 'Computational'], 'computational'), (['a', 'computational', 'Computational', 'processes'], 'process.'), (['computational', 'process.', 'processes', 'are'], 'Computational'), (['process.', 'Computational', 'are', 'abstract'], 'processes'), (['Computational', 'processes', 'abstract', 'beings'], 'are'), (['processes', 'are', 'beings', 'that'], 'abstract'), (['are', 'abstract', 'that', 'inhabit'], 'beings'), (['abstract', 'beings', 'inhabit', 'computers.'], 'that'), (['beings', 'that', 'computers.', 'As'], 'inhabit'), (['that', 'inhabit', 'As', 'they'], 'computers.'), (['inhabit', 'computers.', 'they', 'evolve,'], 'As'), (['computers.', 'As', 'evolve,', 'processes'], 'they'), (['As', 'they', 'processes', 'manipulate'], 'evolve,'), (['they', 'evolve,', 'manipulate', 'other'], 'processes'), (['evolve,', 'processes', 'other', 'abstract'], 'manipulate'), (['processes', 'manipulate', 'abstract', 'things'], 'other'), (['manipulate', 'other', 'things', 'called'], 'abstract'), (['other', 'abstract', 'called', 'data.'], 'things'), (['abstract', 'things', 'data.', 'The'], 'called'), (['things', 'called', 'The', 'evolution'], 'data.'), (['called', 'data.', 'evolution', 'of'], 'The'), (['data.', 'The', 'of', 'a'], 'evolution'), (['The', 'evolution', 'a', 'process'], 'of'), (['evolution', 'of', 'process', 'is'], 'a'), (['of', 'a', 'is', 'directed'], 'process'), (['a', 'process', 'directed', 'by'], 'is'), (['process', 'is', 'by', 'a'], 'directed'), (['is', 'directed', 'a', 'pattern'], 'by'), (['directed', 'by', 'pattern', 'of'], 'a'), (['by', 'a', 'of', 'rules'], 'pattern'), (['a', 'pattern', 'rules', 'called'], 'of'), (['pattern', 'of', 'called', 'a'], 'rules'), (['of', 'rules', 'a', 'program.'], 'called'), (['rules', 'called', 'program.', 'People'], 'a'), (['called', 'a', 'People', 'create'], 'program.'), (['a', 'program.', 'create', 'programs'], 'People'), (['program.', 'People', 'programs', 'to'], 'create'), (['People', 'create', 'to', 'direct'], 'programs'), (['create', 'programs', 'direct', 'processes.'], 'to'), (['programs', 'to', 'processes.', 'In'], 'direct'), (['to', 'direct', 'In', 'effect,'], 'processes.'), (['direct', 'processes.', 'effect,', 'we'], 'In'), (['processes.', 'In', 'we', 'conjure'], 'effect,'), (['In', 'effect,', 'conjure', 'the'], 'we'), (['effect,', 'we', 'the', 'spirits'], 'conjure'), (['we', 'conjure', 'spirits', 'of'], 'the'), (['conjure', 'the', 'of', 'the'], 'spirits'), (['the', 'spirits', 'the', 'computer'], 'of'), (['spirits', 'of', 'computer', 'with'], 'the'), (['of', 'the', 'with', 'our'], 'computer'), (['the', 'computer', 'our', 'spells.'], 'with')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKNnliropI1C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPqVg3GZxGeA"
      },
      "source": [
        "# data에 있는 context(ex:['We', 'are', 'to', 'study'])을 index화 해주고 torch.tensor로 바꿔주겠다\n",
        "word_to_idx = {word:idx for idx, word in enumerate(vocab)}\n",
        "def make_context_vector(context, word_to_idx):\n",
        "    # context에 있는 w를 word_to_idx에서 가져와서 idxs 담겠다.\n",
        "    idxs = [word_to_idx[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "    # torch.long은 보통 인데스 나타낼때 사용하는 data type\n",
        "\n",
        "#     # word_to_idx = {'word':i, ...}\n",
        "# con = ['We', 'are', 'to', 'study']\n",
        "# make_context_vector(con, word_to_idx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpCBgPMmBF9Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ZhzFe8xJlG"
      },
      "source": [
        "class CBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW, self).__init__()\n",
        " \n",
        "        #out: 1 x emdedding_dim\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        #out: 1 x vocab_size\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "        self.activation_function = nn.LogSoftmax(dim = -1)\n",
        "        # LogSoftmax 는 softmax값에 log 취한것, numaric stablity때문\n",
        "\n",
        "    def forward(self, inputs):  #input으로 context가 idx로 변환 tensor가 옴\n",
        "        individual_embeds = self.embeddings(inputs) # 4*100 (4: 2*CONTEXT_SIZE)\n",
        "        # >>> print('ebmeds size: ',individual_embeds.shape) \n",
        "        # ebmeds size:  torch.Size([4, 100])\n",
        "        # embddings을 lookup한 값들 총 4개가 있음\n",
        "        embeds = (1/4)*(individual_embeds[0] + individual_embeds[1] + individual_embeds[2] + individual_embeds[3]) # 100*1 위에 4개를 평균 낸것 \n",
        "        # >>>print('ebmeds of average size: ',embeds.shape)\n",
        "        # ebmeds of average size:  torch.Size([100]) \n",
        "        embeds = embeds.view(1,-1) # 1*100 형태를 reshape해주는것\n",
        "        z = self.linear(embeds)\n",
        "        log_y_hat = self.activation_function(z)\n",
        "        return log_y_hat\n",
        "\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.tensor([word_to_idx[word]],dtype=torch.long)\n",
        "        return self.embeddings(word).view(1,-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL5_V8IrxOLD"
      },
      "source": [
        "model = CBOW(vocab_size, EMDEDDING_DIM).to(device)\n",
        "\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# TRAINING\n",
        "for epoch in range(55):\n",
        "    total_loss = 0\n",
        "\n",
        "    for context, target in data:\n",
        "        context_vector = make_context_vector(context, word_to_idx).to(device)  \n",
        "        y = torch.tensor([word_to_idx[target]]).to(device)\n",
        "        \n",
        "        log_y_hat = model(context_vector)\n",
        "\n",
        "        total_loss += loss_function(log_y_hat, y)\n",
        "\n",
        "    #optimize at the end of each epoch\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykIk1OuTxPyB",
        "outputId": "6ca0bd55-3d98-4689-e34e-4a784a5b664e"
      },
      "source": [
        "#TESTING\n",
        "context = ['We','are','to','study']\n",
        "context1 = ['are','about','study','the']\n",
        "context2 = ['Computational','processes','abstract','beings']\n",
        "context_vector = make_context_vector(context, word_to_idx).to(device)\n",
        "context_vector1 = make_context_vector(context1, word_to_idx).to(device)\n",
        "context_vector2 = make_context_vector(context2, word_to_idx).to(device)\n",
        "\n",
        "\n",
        "new_y_hat = model(context_vector)\n",
        "new_y_hat1 = model(context_vector1)\n",
        "new_y_hat2 = model(context_vector2)\n",
        "\n",
        "#Print result\n",
        "print(f'Raw text: {\" \".join(raw_text)}\\n')\n",
        "print(f'Context: {context}\\n')\n",
        "print(f'Prediction: {idx_to_word[torch.argmax(new_y_hat[0]).item()]}')\n",
        "print('\\n')\n",
        "print(f'Context: {context1}\\n')\n",
        "print(f'Prediction: {idx_to_word[torch.argmax(new_y_hat1[0]).item()]}')\n",
        "print('\\n')\n",
        "print(f'Context: {context2}\\n')\n",
        "print(f'Prediction: {idx_to_word[torch.argmax(new_y_hat2[0]).item()]}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw text: We are about to study the idea of a computational process. Computational processes are abstract beings that inhabit computers. As they evolve, processes manipulate other abstract things called data. The evolution of a process is directed by a pattern of rules called a program. People create programs to direct processes. In effect, we conjure the spirits of the computer with our spells.\n",
            "\n",
            "Context: ['We', 'are', 'to', 'study']\n",
            "\n",
            "Prediction: about\n",
            "\n",
            "\n",
            "Context: ['are', 'about', 'study', 'the']\n",
            "\n",
            "Prediction: to\n",
            "\n",
            "\n",
            "Context: ['Computational', 'processes', 'abstract', 'beings']\n",
            "\n",
            "Prediction: are\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZafKAuf_xTsK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}